{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bdq8ydSd4xUy"
   },
   "source": [
    "# Tugas Prapraktikum\n",
    "\n",
    "Tugas Prapraktikum dikerjakan dengan _dataset_ [Rain in Australia](https://www.kaggle.com/datasets/jsphyg/weather-dataset-rattle-package/download?datasetVersionNumber=2). Tanpa meninjau waktu (`date`), prediksi status hujan pada keesokan harinya (`RainTomorrow`). Berikan nilai `1` jika diprediksi hujan pada keesokan harinya, `0` jika tidak.\n",
    "\n",
    "<br>\n",
    "Tugas dikerjakan secara berkelompok. Setiap kelompok terdiri atas 2 (dua) mahasiswa. Kumpulkan paling lambat pada Minggu, 16 April 2023, pukul 23:59 WIB melalui Edunex."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XAHqneEY7b7b"
   },
   "source": [
    "# 0. Persiapan Data and Pustaka"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install and import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zsBbpcIi7fHi"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import cross_validate, GridSearchCV\n",
    "from sklearn.ensemble import VotingClassifier, StackingClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OWLkjeKo7gdD"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('weatherAUS.csv')\n",
    "df = df.drop(['Date'], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JYGzyrantR1r"
   },
   "source": [
    "# I. Pemahaman Data\n",
    "Tujuan dari bagian ini adalah peserta dapat memahami kualitas dari data yang diberikan. Hal yang diliputi adalah sebagai berikut:\n",
    "1. Ukuran data\n",
    "2. Statistik dari tiap fitur\n",
    "3. Pencilan (_outlier_)\n",
    "4. Korelasi\n",
    "5. Distribusi "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8SMf9-ikuoCe"
   },
   "source": [
    "## I.1 \n",
    "Carilah:\n",
    "1. Ukuran dari data (instansi dan fitur)\n",
    "2. Tipe dari setiap fitur \n",
    "3. Banyak nilai unik dari fitur yang bertipe kategorikal\n",
    "4. Nilai minimum, maksimum, rata-rata, median, dan standar deviasi dari fitur nonkategorikal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SAxrfZySuM3-"
   },
   "outputs": [],
   "source": [
    "# I.1 Kode di sini.\n",
    "\n",
    "# 1. Ukuran dari data (instansi dan fitur)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Tipe dari setiap fitur\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Banyak nilai unik dari fitur yang bertipe kategorikal\n",
    "df.select_dtypes(include=['object']).nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Nilai minimum, maksimum, rata-rata, median, dan standar deviasi dari fitur nonkategorikal\n",
    "df.select_dtypes(include=['float64']).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VE1l_gOTwHuz"
   },
   "source": [
    "## I.2\n",
    "Carilah:\n",
    "1. Nilai hilang (_missing_) dari setiap fitur\n",
    "2. Nilai pencilan (_outlier_) dari setiap fitur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IGe-YWAvwQDr"
   },
   "outputs": [],
   "source": [
    "# I.2 Kode di sini.\n",
    "\n",
    "# 1. Nilai hilang (missing) dari setiap fitur\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Nilai pencilan (outlier) dari setiap fitur\n",
    "\n",
    "q1 = df.select_dtypes(include=['float64']).quantile(0.25)\n",
    "q3 = df.select_dtypes(include=['float64']).quantile(0.75)\n",
    "iqr = q3 - q1\n",
    "\n",
    "minimum_range = q1 - 1.5 * iqr\n",
    "maximum_range = q3 + 1.5 * iqr\n",
    "\n",
    "# Nilai outlier cuman bisa di type number\n",
    "((df.select_dtypes(include=['float64']) < minimum_range) | (df.select_dtypes(include=['float64']) > maximum_range)).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8tUGStQ_wR4P"
   },
   "source": [
    "## I.3\n",
    "Lakukan:\n",
    "1. Pencarian korelasi antarfitur\n",
    "2. Visualisasi distribusi setiap fitur (kategorikal dan kontinu)\n",
    "3. Visualisasi distribusi setiap fitur per target (`RainTomorrow`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XoBqyQA1wRNX"
   },
   "outputs": [],
   "source": [
    "# I.3 Kode di sini.\n",
    "\n",
    "# 1. Pencarian korelasi antar fitur\n",
    "print(df.select_dtypes(include=['float64']).corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Visualisasi distribusi setiap fitur (kategorikal dan kontinu)\n",
    "\n",
    "# Kontinu\n",
    "df.hist(figsize=(20, 20))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kategorikal\n",
    "for col in df.select_dtypes(include=['object']):\n",
    "    df[col].value_counts().plot(kind='bar')\n",
    "    plt.title(col)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kV3BDt235mdz"
   },
   "source": [
    "## I.4\n",
    "Lakukanlah analisis lebih lanjut jika diperlukan, kemudian lakukan hal berikut:\n",
    "1. Penambahan fitur jika memungkinkan\n",
    "2. Pembuangan fitur yang menurut kalian tidak dibutuhkan\n",
    "3. Penanganan nilai hilang\n",
    "4. Transformasi data kategorikal menjadi numerikal (_encoding_)\n",
    "5. _Scaling_ dengan `MinMaxScaler`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jlTGspG_56re"
   },
   "outputs": [],
   "source": [
    "# I.4 Put your code here\n",
    "\n",
    "# 1. Penambahan fitur jika memungkinkan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Pembuangan fitur yang menurut kalian tidak dibutuhkan\n",
    "df = df.drop(['Location', 'WindGustDir', 'WindDir9am', 'WindDir3pm', 'RainToday'], axis=1)\n",
    "\n",
    "for col in df:\n",
    "    if df[col].isnull().sum() > 10000:\n",
    "        df = df.drop([col], axis=1)\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Penanganan nilai hilang\n",
    "# Yang kategorikal pake modus\n",
    "for col in df.select_dtypes(include=['object']).columns:\n",
    "    df[col] = df[col].fillna(df[col].mode()[0])\n",
    "\n",
    "# Yang numerikal pake mean\n",
    "for col in df.select_dtypes(include=['float64']).columns:\n",
    "    df[col] = df[col].fillna(df[col].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Transformasi data kategorikal menjadi numerikal (encoding)\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "obj = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "for col in df.select_dtypes(include=['object']).columns:\n",
    "    df[col] = encoder.fit_transform(df[col])\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Scaling dengan MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "df_scaled = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n",
    "print(df_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mt2zHZRauLIm"
   },
   "source": [
    "# II. Desain Eksperimen\n",
    "Tujuan dari bagian ini adalah peserta dapat memahami cara melakukan eksperimen mencari metode terbaik dengan benar. Hal yang diliputi adalah sebagai berikut:\n",
    "1. Pembuatan model\n",
    "2. Proses validasi\n",
    "3. _Hyperparameter tuning_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kf4xsl8RydIt"
   },
   "source": [
    "## II.1\n",
    "Tentukanlah metrik yang akan digunakan pada eksperimen kali ini. Metrik yang dapat lebih dari satu jenis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S2I0axfj4OuC"
   },
   "source": [
    "(Tuliskan jawaban bagian II.1 di sini.)\n",
    "\n",
    "> Matriks yang akan digunakan adalah nilai akurasi, precision, recall, dan juga nilai F1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FONT0OyUyoQG"
   },
   "source": [
    "## II.2 \n",
    "Bagi data dengan perbandingan 0,8 untuk data latih dan 0,2 untuk data validasi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gqa9nn5muMS2"
   },
   "outputs": [],
   "source": [
    "# II.2 Kode di sini\n",
    "\n",
    "X = df_scaled.drop(['RainTomorrow'], axis=1)\n",
    "y = df_scaled['RainTomorrow']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V4yS8O3tyyyh"
   },
   "source": [
    "## II.3\n",
    "Lakukan hal berikut:\n",
    "1. Prediksi dengan menggunakan model _logistic regression_ sebagai _baseline_.\n",
    "2. Tampilkan evaluasi dari model yang dibangun dari metrik yang ditentukan pada II.1\n",
    "3. Tampilkan _confusion matrix_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EpEqAz94yyQo"
   },
   "outputs": [],
   "source": [
    "# II.3 Kode di sini\n",
    "\n",
    "model = LogisticRegression(max_iter=10000).fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print('Precision: ', precision_score(y_test, y_pred))\n",
    "print('Recall: ', recall_score(y_test, y_pred))\n",
    "print('F1: ', f1_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aFB2AlZfzU54"
   },
   "source": [
    "## II.4 \n",
    "Lakukanlah:\n",
    "1. Pembelajaran dengan model lain\n",
    "2. _Hyperparameter tuning_ untuk model yang dipakai dengan menggunakan _grid search_ (perhatikan _random factor_ pada beberapa algoritma model)\n",
    "3. Validasi dengan _cross validation_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "df0YVJ7dzUSc"
   },
   "outputs": [],
   "source": [
    "# II.4 Kode di sini.\n",
    "\n",
    "# ndak tau modelnya yg mana, aing pake neural ae\n",
    "svc = SVC()\n",
    "\n",
    "param = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'gamma': [0.1, 1],\n",
    "    'kernel': ['linear', 'rbf']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(svc, param, cv=5, scoring='accuracy').fit(X_train, y_train)\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "svc2 = SVC(**grid_search.best_params_).fit(X_train, y_train)\n",
    "y_pred = svc2.predict(X_test)\n",
    "\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print('Precision: ', precision_score(y_test, y_pred))\n",
    "print('Recall: ', recall_score(y_test, y_pred))\n",
    "print('F1: ', f1_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_validate(svc, X_test, y_test, cv=5, scoring=('accuracy', 'precision', 'recall', 'f1'))\n",
    "\n",
    "print('Accuracy: ', scores['test_accuracy'].mean())\n",
    "print('Precision: ', scores['test_precision'].mean())\n",
    "print('Recall: ', scores['test_recall'].mean())\n",
    "print('F1: ', scores['test_f1'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ePIGuRZuNZb"
   },
   "source": [
    "# III. Improvement\n",
    "Pada bagian ini, kalian diharapkan dapat:\n",
    "1. melakukan pelatihan dengan data hasil _oversampling_ / _undersampling_, disertai dengan validasi yang benar; serta\n",
    "2. menerapkan beberapa metode untuk menggabungkan beberapa model.\n",
    "\n",
    "Kedua hal ini adalah contoh metode untuk meningkatkan kinerja dari model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NGgjXVqf1vhN"
   },
   "source": [
    "## III.1\n",
    "Lakukanlah:\n",
    "1. _Oversampling_ pada kelas minoritas pada data latih\n",
    "2. _Undersampling_ pada kelas mayoritas pada data latih\n",
    "\n",
    "Pada setiap tahap, latih dengan model *baseline* (II.3), dan validasi dengan data validasi. Data latih dan validasi adalah data yang disusun pada bagian II.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bLLLsyoF2GIM"
   },
   "outputs": [],
   "source": [
    "# III.1 Kode di sini.\n",
    "\n",
    "# Oversampling\n",
    "smote = SMOTE(random_state=12)\n",
    "OX_train, Oy_train = smote.fit_resample(X_train, y_train)\n",
    "print(OX_train.shape)\n",
    "\n",
    "model = LogisticRegression(max_iter=10000).fit(OX_train, Oy_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print('Precision: ', precision_score(y_test, y_pred))\n",
    "print('Recall: ', recall_score(y_test, y_pred))\n",
    "print('F1: ', f1_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validasi\n",
    "scores = cross_validate(model, X_test, y_test, cv=5, scoring=('accuracy', 'precision', 'recall', 'f1'))\n",
    "\n",
    "print('Accuracy: ', scores['test_accuracy'].mean())\n",
    "print('Precision: ', scores['test_precision'].mean())\n",
    "print('Recall: ', scores['test_recall'].mean())\n",
    "print('F1: ', scores['test_f1'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undersampling\n",
    "rus = RandomUnderSampler(random_state=12)\n",
    "UX_train, Uy_train = rus.fit_resample(X_train, y_train)\n",
    "print(UX_train.shape)\n",
    "\n",
    "model = LogisticRegression(max_iter=10000).fit(UX_train, Uy_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print('Precision: ', precision_score(y_test, y_pred))\n",
    "print('Recall: ', recall_score(y_test, y_pred))\n",
    "print('F1: ', f1_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_validate(model, X_test, y_test, cv=5, scoring=('accuracy', 'precision', 'recall', 'f1'))\n",
    "\n",
    "print('Accuracy: ', scores['test_accuracy'].mean())\n",
    "print('Precision: ', scores['test_precision'].mean())\n",
    "print('Recall: ', scores['test_recall'].mean())\n",
    "print('F1: ', scores['test_f1'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FtbGHN3P2Fxe"
   },
   "source": [
    "## III.2\n",
    "Lakukanlah:\n",
    "1. Eksplorasi _soft voting_, _hard voting_, dan _stacking_.\n",
    "2. Buatlah model _logistic regression_ dan SVM.\n",
    "3. Lakukanlah _soft voting_ dari model-model yang dibangun pada poin 2.\n",
    "4. Lakukan _hard voting_ dari model-model yang dibangun pada poin 2.\n",
    "5. Lakukanlah _stacking_ dengan _final classifier_ adalah _logistic regression_ dari model-model yang dibangun pada poin 2.\n",
    "6. Lakukan validasi dengan metrics yang telah ditentukan untuk poin 3, 4, dan 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NfGqy72SAZ-t"
   },
   "source": [
    "(Tuliskan hasil eksplorasi III.2 poin 1 di sini.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zdchguBQtErx"
   },
   "outputs": [],
   "source": [
    "# III.2 Kode di sini.\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "svm = SVC(probability=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Soft Voting\n",
    "model = VotingClassifier(estimators=[('lr', lr), ('svm', svm)], voting='soft')\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print('Precision: ', precision_score(y_test, y_pred))\n",
    "print('Recall: ', recall_score(y_test, y_pred))\n",
    "print('F1: ', f1_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "scores = cross_validate(model, X_test, y_test, cv=5, scoring=('accuracy', 'precision', 'recall', 'f1'))\n",
    "\n",
    "print('Accuracy: ', scores['test_accuracy'].mean())\n",
    "print('Precision: ', scores['test_precision'].mean())\n",
    "print('Recall: ', scores['test_recall'].mean())\n",
    "print('F1: ', scores['test_f1'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hard Voting\n",
    "model = VotingClassifier(estimators=[('lr', lr), ('svm', svm)], voting='hard')\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print('Precision: ', precision_score(y_test, y_pred))\n",
    "print('Recall: ', recall_score(y_test, y_pred))\n",
    "print('F1: ', f1_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "scores = cross_validate(model, X_test, y_test, cv=5, scoring=('accuracy', 'precision', 'recall', 'f1'))\n",
    "\n",
    "print('Accuracy: ', scores['test_accuracy'].mean())\n",
    "print('Precision: ', scores['test_precision'].mean())\n",
    "print('Recall: ', scores['test_recall'].mean())\n",
    "print('F1: ', scores['test_f1'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = StackingClassifier(estimators=[('lr', lr), ('svm', svm)], final_estimator=LogisticRegression(max_iter=10000))\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print('Precision: ', precision_score(y_test, y_pred))\n",
    "print('Recall: ', recall_score(y_test, y_pred))\n",
    "print('F1: ', f1_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "scores = cross_validate(model, X_test, y_test, cv=5, scoring=('accuracy', 'precision', 'recall', 'f1'))\n",
    "\n",
    "print('Accuracy: ', scores['test_accuracy'].mean())\n",
    "print('Precision: ', scores['test_precision'].mean())\n",
    "print('Recall: ', scores['test_recall'].mean())\n",
    "print('F1: ', scores['test_f1'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "unmFXb-73OMD"
   },
   "source": [
    "# IV. Analisis\n",
    "Bandingkan hasil dari hal-hal berikut:\n",
    "1. Model _baseline_ (II.3)\n",
    "2. Model lain (II.4)\n",
    "3. Hasil _undersampling_\n",
    "4. Hasil _oversampling_\n",
    "5. Hasil _soft voting_\n",
    "6. Hasil _hard voting_\n",
    "7. Hasil _stacking_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e9x0VH2AAkwZ"
   },
   "source": [
    "(Tuliskan jawaban bagian IV di sini.)\n",
    "\n",
    "## IV.1\n",
    "\n",
    "## IV.2\n",
    "\n",
    "## IV.4\n",
    "\n",
    "## IV.5\n",
    "\n",
    "## IV.6\n",
    "\n",
    "## IV.7\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Tugas Pendahuluan IF3270.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
